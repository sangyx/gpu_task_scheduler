# GPU Task Scheduler

A simple Python utility that helps schedule and execute shell commands on available GPUs using `nvidia-smi`. It supports custom GPU selection and concurrency limits per GPU.

## ğŸ“¦ Installation

```bash
pip install .
```

## ğŸš€ Usage Example

```python
from gpu_task_scheduler import GPUTaskScheduler

tasks = [
    "python train_model.py --epochs 10",
    "bash run_simulation.sh",
    "python evaluate.py --model checkpoint.pth"
]

scheduler = GPUTaskScheduler(
    wait_interval=10,
    allowed_gpu_ids=[0, 1],
    max_tasks_per_gpu=2
)
scheduler.run_tasks(tasks)
```

## âš™ï¸ Parameters

### `GPUTaskScheduler(wait_interval=10, allowed_gpu_ids=None, max_tasks_per_gpu=1)`

| Parameter           | Type        | Default | Description |
|---------------------|-------------|---------|-------------|
| `wait_interval`     | `int`       | `10`    | Number of seconds to wait before checking again if no GPU is available. |
| `allowed_gpu_ids`   | `list[int]` | `None`  | List of GPU indices (e.g., `[0, 1]`) that the scheduler is allowed to use. If `None`, all GPUs are considered. |
| `max_tasks_per_gpu` | `int`       | `1`     | Maximum number of concurrent tasks allowed on a single GPU. Helps share GPU among multiple tasks. |

## ğŸ› ï¸ Requirements

- Python 3.6+
- `nvidia-smi` available in PATH (NVIDIA drivers installed)

## ğŸ“ Project Structure

```
gpu_task_scheduler/
â”œâ”€â”€ gpu_task_scheduler/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ scheduler.py
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ run_tasks.py
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â””â”€â”€ pyproject.toml (optional)
```